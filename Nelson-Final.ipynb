{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Prediction with Neural Networks\n",
    "**Bennett Nelson - CS440 Final Project**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Although I have enjoyed learning about many topics from the realm of AI over the course of the semester, neural networks caught my attention most prominently. This is in large part due to the many useful applications for this technology that come to my mind. However, neural networks have been, admittedly, the most difficult concept for me to grasp out of the various algorithms that were covered throughout the semester. From my perspective, this project seems like a great opportunity for me to challenge myself and solidify my understanding of neural networks, which will hopefully allow me to use them to greater effect in the future.\n",
    "\n",
    "In order to explore both the creation and capabilities of neural networks to a greater extent, I have decided to use them in a rather largescale problem: Stock Price Prediction. I believe that this problem will serve as a detailed look at the strengths and limitations of regression neural networks as well as a useful comparison between the accuracies and efficiencies of various network complexities and optimization algorithms for those networks. Due to the scale of the stock prediction problem, there will be many datasets available given the amount of stocks in the market, and there will plenty of variability between these datasets to analyze. For example, differences in industry or even the resolution of time when data is collected in a set can be tested. Overall, the main goal in working with this problem is to explore key variables in neural networks such as optimization algorithms, hidden layer complexities, network sizes, and sizes of training datasets in order to predict something as complex as a stock price with as much accuracy as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data\n",
    "Before any neural networks can be compared, used, or even trained, an efficient method of gathering historical stock price and indicator data must be found. Originally, I had planned on using data from a popular investment research organization known as Morningstar. Their website includes charting tools which also allow for the exporting of a stock's closing prices over a given amount of time in CSV format. While this information would certainly be helpful, it is not enough for my purposes, and the export process is more tedious than I would have liked. Therefore, I began searching for another solution, which I found in a free-to-use stock API called Alpha Vantage.\n",
    "\n",
    "Using Alpha Vantage provides very quick and easy access to a variety of statistics about any given stock. For example, a stock's open, high, low, and close prices, as well as trading volume, can be rapidly collected into a CSV file with the option of selecting a time interval for how often (or how many) data points are gathered for that stock. Data can be taken as specifically as 1 minute per update or as broadly as 1 month per update. This will allow me to have great control over what is included in each dataset for a stock. In addition to data about a stock's price and trading volume, Alpha Vantage also provides access to popular technical indicators used by traders to predict the direction a stock will move.\n",
    "\n",
    "\n",
    "### Technical Indicators\n",
    "In the investment world, technical analysis is a method of trading which involves the careful studying of price and volume as well as a great variety of models, known as technical indicators, based on the behaviors of these statistics. Although there are seemingly endless indicators to choose from, I have decided to focus on 5 of the most widely-used as they are simple yet have the potential to be greatly effective. The datasets for the stocks tested will include the following indicators:\n",
    "\n",
    "- **Relative Strength Index (RSI):** Using closing prices for a recent trading period, the RSI is used to determine past and present strength or weakness for a stock.\n",
    "\n",
    "- **Moving Average Convergence Divergence (MACD):** In order to detect potential changes in a stock's strength or direction, the MACD indicator uses two exponential moving averages (a short-term average and a long-term average). Crossovers, divergences, and the overall positions of these two averages relative to each other can be used as signals for a stock's behavior.\n",
    "\n",
    "- **Bollinger Bands:** A simple moving average is calculated from recent stock price data as well as two standard deviations above and below this average. The position of the stock's price within this range of standard deviations as well as the sizes of the standard deviations themselves can indicate overbought or oversold conditions.\n",
    "\n",
    "- **Stochastic Oscillator:** To predict a stock's momentum, this indicator compares the stock's closing price to the range of its prices over a period of time. Its sensitivity can be manipulated by changing the length of this period of time. It is often used in many of the same ways as the RSI.\n",
    "\n",
    "- **Commodity Channel Index (CCI):** The CCI can be used to detect patterns in a stock's behavior as well as to indicate overbought or oversold conditions. This is accomplished by finding the difference between the price of the stock and a moving average and dividing this difference by 1.5% of a normal deviation from that average.\n",
    "\n",
    "\n",
    "### Simplifying Data Collection\n",
    "Because I will want to use my neural networks with a variety of different stocks over several different time periods, I will define some python functions to accomplish making the API calls and compiling one CSV datafile from the several files that the API returns. Then, I will be ready to start constructing my neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request # Used for interacting with Alpha Vantage API and downloading files\n",
    "import os # Checking if files exist and deleting unneeded files\n",
    "from time import sleep # Must wait 1 minute after making 5 API calls\n",
    "import csv # Simple reading, manipulating, and writing of CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `createStockCSV()`\n",
    "This function makes the gathering of historical data about a given stock very simple. It takes a fileName, for the CSV file to be outputted, as well as several parameters needed for the API calls. These include the stock's ticker symbol (stockSymbol), the frequency with which datapoints should be taken (timeSeries), the amount of data points ahead to match the current point with as needed by the neural networks (futureDataPoints), and a timeInterval which is used when the timeSeries is intraday (essentially a more specific timeSeries).\n",
    "\n",
    "createStockCSV() downloads all necessary files in CSV format, these being price data and data for the 5 technical indicators, for the stock specified with the stockSymbol parameter. It then calls concatCSV() and createFutureColumn() to create one final CSV comprised of the data found in the separate files. Finally, the separate files are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createStockCSV(fileName, stockSymbol, timeSeries, futureDataPoints, timeInterval=\"1min\"):\n",
    "    if (not os.path.exists(\"./\" + fileName)):\n",
    "        stockSymbol = stockSymbol.upper()\n",
    "        timeSeries = timeSeries.upper()\n",
    "        timeInterval = timeInterval.lower()\n",
    "\n",
    "        priceURL = \"https://www.alphavantage.co/query?function=TIME_SERIES_\" + timeSeries + \"&symbol=\" +\\\n",
    "        stockSymbol + \"&apikey=DJ74AP0344E00KXN&datatype=csv&outputsize=full\"\n",
    "        if (timeSeries == \"INTRADAY\"):\n",
    "            priceURL = priceURL + \"&interval=\" + timeInterval\n",
    "        urllib.request.urlretrieve(priceURL, \"./priceData.csv\")\n",
    "\n",
    "        rsiURL = \"https://www.alphavantage.co/query?function=RSI&symbol=\" + stockSymbol + \"&interval=\" +\\\n",
    "        (timeInterval if (timeSeries == \"INTRADAY\") else timeSeries.lower()) +\\\n",
    "        \"&time_period=10&series_type=close&apikey=DJ74AP0344E00KXN&datatype=csv\"\n",
    "        urllib.request.urlretrieve(rsiURL, \"./rsiData.csv\")\n",
    "\n",
    "        macdURL = \"https://www.alphavantage.co/query?function=MACD&symbol=\" + stockSymbol + \"&interval=\" +\\\n",
    "        (timeInterval if (timeSeries == \"INTRADAY\") else timeSeries.lower()) +\\\n",
    "        \"&series_type=close&apikey=DJ74AP0344E00KXN&datatype=csv\"\n",
    "        urllib.request.urlretrieve(macdURL, \"./macdData.csv\")\n",
    "\n",
    "        bandsURL = \"https://www.alphavantage.co/query?function=BBANDS&symbol=\" + stockSymbol + \"&interval=\" +\\\n",
    "        (timeInterval if (timeSeries == \"INTRADAY\") else timeSeries.lower()) +\\\n",
    "        \"&time_period=5&series_type=close&apikey=DJ74AP0344E00KXN&datatype=csv\"\n",
    "        urllib.request.urlretrieve(bandsURL, \"./bandsData.csv\")\n",
    "\n",
    "        sleep(60) # Must wait 1 minute as free version of API only allows 5 calls per minute\n",
    "\n",
    "        stochURL = \"https://www.alphavantage.co/query?function=STOCH&symbol=\" + stockSymbol + \"&interval=\" +\\\n",
    "        (timeInterval if (timeSeries == \"INTRADAY\") else timeSeries.lower()) +\\\n",
    "        \"&apikey=DJ74AP0344E00KXN&datatype=csv\"\n",
    "        urllib.request.urlretrieve(stochURL, \"./stochData.csv\")\n",
    "\n",
    "        cciURL = \"https://www.alphavantage.co/query?function=CCI&symbol=\" + stockSymbol + \"&interval=\" +\\\n",
    "        (timeInterval if (timeSeries == \"INTRADAY\") else timeSeries.lower()) +\\\n",
    "        \"&time_period=10&apikey=DJ74AP0344E00KXN&datatype=csv\"\n",
    "        urllib.request.urlretrieve(cciURL, \"./cciData.csv\")\n",
    "\n",
    "        fileList = [\"./priceData.csv\", \"./rsiData.csv\", \"./macdData.csv\", \"./bandsData.csv\", \"./stochData.csv\", \"./cciData.csv\"]\n",
    "        concatCSV(fileName, fileList)\n",
    "\n",
    "        createFutureColumn(fileName, futureDataPoints)\n",
    "\n",
    "        for file in fileList:\n",
    "            os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `concatCSV()`\n",
    "As a helper function to createStockCSV(), this function simply takes a fileName for its output file as well as a list of CSV file names (fileList). It reads in each CSV file through use of the `csv` module, turning them into python lists. Then, the timestamp column is removed from all CSV data lists except the first as it is unnecessary. The CSV data lists are concatenated together, one line from each file at a time. This has the result of creating a single CSV file comprised of the columns of the separate CSV files once the python list is written to a file using the `csv` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatCSV(finalName, fileList):\n",
    "    csvList = []\n",
    "    for file in fileList:\n",
    "        csvList.append(list(csv.reader(open(file, \"r\"))))\n",
    "\n",
    "    for i in range(1, len(csvList)):\n",
    "        for j in range(len(csvList[i])):\n",
    "            csvList[i][j] = csvList[i][j][1:]\n",
    "    \n",
    "    finalCSV = csvList[0]\n",
    "    for i in range(1, len(csvList)):\n",
    "        finalCSV = [line1 + line2 for (line1, line2) in zip(finalCSV, csvList[i])]\n",
    "    \n",
    "    fileWriter = csv.writer(open(\"./\" + finalName, \"w\"))\n",
    "    fileWriter.writerows(finalCSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `createFutureColumn()`\n",
    "The final step of createStockCSV(), this function adds another column to the datafile which contains the stock's closing price from a set number of data points ahead of each point. This number is specified by the parameter dataPointsAhead. The purpose of adding this column is to give the neural networks target data to train from and predict. The length of time into the future for this price data can be changed for the same stock, and I will experiment with different values to determine how it affects the networks' prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFutureColumn(dataFile, dataPointsAhead):\n",
    "    data = list(csv.reader(open(dataFile, \"r\")))\n",
    "    data[0].append(\"Future_Date\")\n",
    "    data[0].append(\"Future_Price\")\n",
    "    for i in range(len(data) - 1, dataPointsAhead, -1):\n",
    "        data[i].append(data[i - dataPointsAhead][0])\n",
    "        data[i].append(data[i - dataPointsAhead][4])\n",
    "    \n",
    "    fileWriter = csv.writer(open(\"./\" + dataFile, \"w\"))\n",
    "    fileWriter.writerow(data[0])\n",
    "    for i in range(1, len(data)):\n",
    "        if (len(data[i]) == len(data[len(data) - 1])):\n",
    "            fileWriter.writerow(data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The First Dataset\n",
    "Now that all aspects of the createStockCSV() function are complete, I can use it to create the dataset for the first stock I will test. I have decided to start with Starbucks (SBUX) as it is a well-known, stable company with a long history of price data. For the first test, I will set the time interval to daily, giving the neural networks a good amount of samples to work with. I will also start by attempting to predict prices 1 month ahead, in order to get a baseline for how well the networks perform with what they have been given. Running the below line will create a custom CSV file fitting these specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "createStockCSV(\"SBUX_daily_30_data.csv\", \"SBUX\", \"daily\", 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def trainNetwork(X, T, learningRate, numHiddenLayers, numIterations, optimizerName):\n",
    "    \n",
    "    class StockNN(torch.nn.module):\n",
    "        def __init__(self, numInputs, numHiddenUnits, numOutputs):\n",
    "            super(StockNN, self).__init__()\n",
    "            self.hidden = torch.nn.Linear(numInputs, numHiddenUnits)\n",
    "            self.tanh = torch.nn.Tanh()\n",
    "            self.output = torch.nn.Linear(numHiddenUnits, numOutputs)\n",
    "            \n",
    "        def forwardPass(self, X):\n",
    "            out = self.hidden(X)\n",
    "            out = self.tanh(out)\n",
    "            out = self.output(out)\n",
    "            return out\n",
    "        \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Running on\", device)\n",
    "    \n",
    "    stockNN = StockNN(1, numHiddenLayers, 1).to(device).double()\n",
    "    \n",
    "    available_optimizers = {\"SGD\": torch.optim.SGD, \"ADAM\": torch.optim.Adam }\n",
    "    optimFunc = available_optimizers[optimizerName]\n",
    "    optimizer = optimFunc(stockNN.parameters(), lr=learningRate)\n",
    "    lossFunc = torch.nn.MSELoss()\n",
    "    \n",
    "    errors = []\n",
    "    startTime = time.time()\n",
    "    \n",
    "    for iteration in range(numIterations):\n",
    "        outputs = stockNN(Xtc)\n",
    "        loss = lossFunc(outputs, Ttc)\n",
    "        errors.append(torch.sqrt(loss))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"Training took {} seconds.\".format(time.time() - startTime))\n",
    "    return stockNN, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-7c3c758e3f34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mXsbux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SBUX_daily_30_data.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mTsbux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SBUX_daily_30_data.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    159\u001b[0m         raise RuntimeError(\n\u001b[1;32m    160\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mFound\u001b[0m \u001b[0mno\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0mon\u001b[0m \u001b[0myour\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mPlease\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0mthat\u001b[0m \u001b[0myou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mGPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minstalled\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0;32mfrom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m http://www.nvidia.com/Download/index.aspx\"\"\")\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;31m# TODO: directly link to the alternative bin that needs install\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "Xsbux = torch.from_numpy(np.loadtxt(\"SBUX_daily_30_data.csv\", delimiter=\",\", skiprows=1, usecols=range(1,16))).cuda()\n",
    "Tsbux = torch.from_numpy(np.loadtxt(\"SBUX_daily_30_data.csv\", delimiter=\",\", skiprows=1, usecols=17)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbuxNN, errors_sbuxNN = trainNetwork(Xtc, Ttc, 0.01, 100, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Resources*\n",
    "\\[1\\] https://investopedia.com/  \n",
    "\\[2\\] https://stackabuse.com/download-files-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
